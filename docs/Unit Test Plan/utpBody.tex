% \section{Introduction}
% \subsection{Purpose}
% \subsection{Scope}
% 
% \section{Test Environment \& Conditions}
% 
% %This section should contain items such as testing tools and suites, runtime environments, OS, etc.
% 
% \section{Test Procedures \& Results}
% 
% \subsection{Test 1}
% \subsubsection{Description}
% \subsubsection{Pre-Conditions}
% \subsubsection{Post-Conditions}
% \subsubsection{Inputs}
% \subsubsection{Outputs}
% 
% %More tests go here 
% 
% \section{Test Summary}
% %This section provides a summary of the test scope and results. A table should be provided of all the tests conducted with an indication of pass/fail.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%% GUIDELINES %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%	Make the plan concise. Avoid redundancy and superfluousness. 
% 	If you think you do not need a section that has been mentioned 
% 	in the template, go ahead and delete that section in your 
% 	test plan.
% 	
% 	Be specific. For example, when you specify an operating system 
% 	as a property of a test environment, mention the OS Edition/Version 
% 	as well, not just the OS Name.
%  	
%	Make use of lists and tables wherever possible. Avoid lengthy 
% 	paragraphs.
% 
%	Have the test plan reviewed a number of times prior to baselining 
% 	it or sending it for approval. The quality of your test plan speaks 
% 	volumes about the quality of the testing you or your team is going to 
% 	perform.
% 	
%	Update the plan as and when necessary. An out-dated and unused 
% 	document stinks and is worse than not having the document in the 
% 	first place.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
The functions within the Reporting module in the Research Support System will be tested with unit tests to determine whether the pre and post conditions specified in the service contracts were met by the module. A plan of said tests are provided in this report. The non functional requirements of the system will also be tested/ evaluated and are also described in this report. 
\subsection{Purpose}
The purpose of this document is to give an overview of the test plan for the reporting module. This document will outline the approaches used to test the module. Functional as well as non-functional requirements will be tested. This document will give an indication as to how well the reporting module of the system performs. It will also provide a list of functionalities to be tested and their respective results. This test plan will focus on the requirements outlined in the software requirements specification(SRS) instead of the requirements implamented in the reporting module. 
\subsection{Scope}
\begin{enumerate}
%Needs to be updated according to final structure
	\item Provide an overview of the test plan.
		
The remainder of this document is structured as follows. It will give references to related documents. This document will   list the features to be tested for both functional and non-functional requirements, it will also list features that will not be tested and reasons thereof. The approach to testing will be mentioned, the passing and failing of tests will be given and for all tests the respective suspension and resumption criteria will be stated. References to supporting work on this test plan will be supplied. The test environment will be outlined. Test efforts/costs will be estimated. The training of staff involved to use the system will be mentioned and the responsibilities of the different users will be mentioned. The risks involved in using this system as well as contingency plans will be given. Assumptions and dependencies of this test plan will be mentioned, and the approvers of this test plan will be listed.

	\item Specify the goals/objectives.

The goal of this test plan is to identify possible flaws in the implementation of the reporting module. If flaws are found they will be detailed in this report. The aim would then be for the implementers to either complete unmet requirements or to fix the implementation of identified incorrect code.

	\item Specify any constraints.

The constraints of developing a test plan for this module is the vague documentation of this module given in the SRS. 
\end{enumerate} 
\section{References} 
\begin{enumerate}
	\item List the related documents, with links to them if available, including the following:

\begin{enumerate}
	\item Project Plan
	\item Configuration Management Plan
\end{enumerate}
\end{enumerate}

\section{Test Items}

\begin{enumerate}
	\item List the test items (software/products) and their versions.
	\item 
\end{enumerate}

\section{Features to be Tested (This section was merged with the approach section)}

The features to be tested are firstly 
Describe the overall approach for the level of testing. For each major feature or group of features,
specify the approach that will ensure that they are adequately tested. The approach may be described in
sufficient detail to permit identification of the major testing tasks and estimation of the time required to
do each one.\\\\
Features to be tested (LTP Section 2.3), features not to be tested (LTP Section 2.4), and approaches
(LTP Section 2.5) are commonly combined in a table called a Test Matrix. It contains a unique
identifier for each requirement for the test (e.g., system and/or software requirements, design, or code),
an indication of the source of the requirement (e.g., a paragraph number in the source document), and a
summary of the requirement and an identification of one or more generic method(s) of test. (as a method we can and should only use black box testing)\\\\

The original IEEE 829 document also has a Test Traceability Matrix section. And it suggests the following at this sections: The Test Matrix may be combined with the Test Traceability Matrix. The Test Traceability Matrix
links each requirement with one or more test cases.\\\\

I really think we could combine these sections like the above suggests into a table. But we could also just reference the test cases in the same table. The test cases could then reside in a section called Test Identification. What do you think of the following outline for this section:\\\\

\subsection{Functional}
The approach taken for the functional requirements testing is a black box testing approach. This means that the functionality of the application is tested without considering the internal implementation. Hence, one is aware of what the specific module should be able to accomplish but not how the module accomplishes it. Test cases are established based on the Software Requirements Specifications and the pre and post conditions for the Reporting module. Both negative and positive tests will be conducted. There are two main services, firstly to generate a report based on the progress status of the publications and secondly to create a report with information regarding all accreditation units active within a specified time period. Tests will be created to test whether the Reporting module performs the right functions to provide these services accurately.
\\\\  
Then we tabulate each feature and provide a reference to the use cases (in Test Identification section) that were identified for each requirement/feature. Where there are no sources to reference for requirements (it's not in the Master Spec) we have to state that it's an assumption. Where do you guys propose we detail these assumptions because Mrs Vreda said we should state them clearly.\\\\


\begin{tabular}{ l|l|l|l } 
	\hline
	\textbf{Feature ID} & \textbf{SRS Source} & \textbf{Summary} & \textbf{Test Case ID}\\
	\hline
	\hline
	viewReportByGroup & Section x.y & short description &\begin{tabular}[t]{@{}l@{}}
		TC01\\
		TC02\\
		TC03\\		
	\end{tabular}\\
	\hline
	somethingConjured & Assumed & short descriptinon & TC04\\
	\hline
	\hline
\end{tabular}	

\subsection{Non-Functional}

\section{Features not to be Tested}

\begin{enumerate}
	\item List the features of the software/product which will not be tested.
	\item Specify the reasons these features wonâ€™t be tested.
\end{enumerate}

\section{Test Identification}

Here we can then list each and every test that we want to perform. Mostly functional tests, but it could also be non-functional.\\\\

This is what Paul had with Test 1, precondition, post-condition etc. IEEE has the following in that section:
\begin{itemize}
	\item  Objective - Identify and briefly describe the special focus or objective for the test case or a series of test cases.
This is much more detailed than the Test Items in the Level Test Plan. It may include the risk or priority for this particular test case or series of test cases.
	\item  Inputs - Specify each input required to execute each test case. Some inputs will be specified by value (with
tolerances where appropriate), whereas others, such as constant tables or transaction files, will be
specified by name. Identify all appropriate databases, files, terminal messages, memory resident areas,
and values passed by the operating system.
	\item  Outcome(s) - Specify all outputs and the expected behavior (e.g., response time) required of the test items. Provide
the exact value (s) (with tolerances where appropriate) for each required output and expected behavior.
This section is not required for self-validating tests.
\end{itemize}

Which we can again tabulate if you want: \\\\
\begin{tabular}{ L{3cm}| L{3cm}| L{3cm}| L{3cm}| L{0cm}} 
	\hline      
	\textbf{Test Case ID} & \textbf{Objective} & \textbf{Inputs} & \textbf{Outcome}\\
	\hline 
	\hline
	View Research Group Report  &  
	The objective for this test case is to test that a report can be generated for a specific research group that the user can specify on the form & 
	The inputs required to execute this test case are the user's selection of a particular research group. This is an optional field and if it is not selected, a report will be generated for the entire department. & 
	The outcome of this test case should be that a report is generated for the specified research group & \\
	\hline 
View Report For Specific Lifecycle State  &  
	The objective for this test case is to test that a report can be generated for a specific life cycle state that the user can select on the form. A lifecycle state refers to the current status of the paper i.e. accepted, submitted, published. Hence a report will be generated displaying the papers of the selected state only & 
	The inputs required to execute this test case are the user's selection of a particular lifecycle state. This is an optional field and if it is not selected, a report will be generated including all utilized states . & 
	The outcome of this test case should be that a report is generated for the specified lifecycle state & \\ 
	\hline 
View Department Report &  
	The objective for this test case is to test that a report can be generated for the entire research department.This will also be the default option if users do not select filter options & 
	The inputs required to execute this test case are the user's selection of the option to view report, without selecting filters. & 
	The outcome of this test case should be that a report is generated for the entire department& \\ 
\end{tabular}
\\
\begin{tabular}{ L{3cm}| L{3cm}| L{3cm}| L{3cm}| L{0cm}} 
\hline 
View Report For Specific Publication Type &  
The objective for this test case is to test that a report can be generated for a specific publication type that the user can select on the form. A publication type refers to either a conference paper, journal article or technical papers. Hence a report will be generated displaying the papers of the selected specific publication type & 
	The inputs required to execute this test case are the user's selection of a particular publication type. This is an optional field and if it is not selected, a report will be generated including all utilized publication types . & 
	The outcome of this test case should be that a report is generated for the specified publication type& \\ 
\hline 
View Report For Specific Time Frame &  
The objective for this test case is to test that a report can be generated for a specific time frame that the user can select on the form. & 
	The inputs required to execute this test case are the user's selection of a particular time frame. This is an optional field and if it is not selected, a report will be generated for the entire period. & 
	The outcome of this test case should be that a report is generated for the specified time frame& \\ 
\hline
View Report For Specific Person &  
The objective for this test case is to test that a report can be generated for a specific person, provided the name and surname of said person is entered on the form & 
	The inputs required to execute this test case are the name and surname of the person for whom the report should be generated& 
	The outcome of this test case should be that a report is generated for the specified person& \\ 
\hline	 
\end{tabular}

\section{Item Pass/Fail Criteria}
   
\begin{enumerate}
	\item Specify the criteria that will be used to determine whether each test item (software/product) has passed or failed testing.
\end{enumerate}

\section{Suspension Criteria and Resumption Requirements}

\begin{enumerate}
	\item Specify criteria to be used to suspend the testing activity.
	\item Specify testing activities which must be redone when testing is resumed.
\end{enumerate}

\section{Test Deliverables}

\begin{enumerate}
	\item List test deliverables, and links to them if available, including the following:

\begin{enumerate}
	\item Test Plan (this document itself)
	\item Test Cases
	\item Test Scripts
	\item Defect/Enhancement Logs
	\item Test Reports
\end{enumerate}
\end{enumerate}
~
\section{Test Environment}

\begin{enumerate}
	\item The properties of test environment: hardware, software, network etc.
	\item Web Server - no server used in the code provided
	\item Database - no database used in the code provided
	\item OS - Linux, Windows, IoS etc.
	\item Browser - All browsers
	\item Java Version - version 7
	\item Testing Framework - JUnit
	\item List any testing or related tools.
	\item JUnit - The unit testing framework that will be used to test functional requirements
\end{enumerate}

\section{Risks}
	The following potential risks are found in this module:
\begin{enumerate}
	\item Aggregating data for those whose names are incoherent from publication to publication.
	\item Values  which are out of bounds.
	\item Database is in an unusable state.
	\item Too much data to process at once.
\end{enumerate}

	The following are contingencies which could be used to prevent the potential risks from arising:
\begin{enumerate}

	\item Do a smart lookup on names and research groups.
	\item Always do bounds checking.
	\item Check that the database is in a stable state before attempting to access it.
	\item Use a map-reduce if necessary.
         

\end{enumerate}


\section{Assumptions and Dependencies}

\begin{enumerate}
	\item The first assumption is that the Jasper Report generated by the module consists of tables with columns for the name of person/group, publication name, publication type, organization associated with publication type, lifecycle state.
	\item The second assumption is that the module abides by the service contracts and implements the services as specified in the service contracts. In addition, we assume the pre and post conditions for the module hold and hence these will be tested.
	\item The first dependancy is that since Java EE was used for implementation, a Java testing framework will be used for the tests
\end{enumerate}