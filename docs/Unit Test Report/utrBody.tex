\section{Introduction}

\subsection{Purpose}

\subsection{Scope}
Specify the contents and organization of this document. Include references to any information captured
in automated tools and not contained in this document.

\section{References}
For each test item (in our case, the Reporting module), supply references to the following documents if they exist: Master Test
Plan, Level Test Plan (The unit test plan is all we have), Level Test Design, Level Test Cases, Level Test Procedures, Level Test Logs,
and Anomaly Reports.

Introduce the following subordinate sections. This section provides an overview of the test results, all
of the detailed test results, rationale for all decisions, and the final conclusions and recommendations.

\section{Overview of Test Results}
Summarize the evaluation of the test items. Identify the items tested, indicating their version/revision
level. Indicate the environment in which the testing activities took place, and its impact (if any).

\section{Detailed Test Results}
Summarize the results of testing. Identify all resolved anomalies and summarize their resolutions (or
reference where that information is available). Identify all unresolved anomalies. If anomalies are
deferred, explain (or reference) the process for handling deferrals.\par

Summarize the major testing activities and events. Summarize the relevant metrics collected.
Report any variances of the test items from their specifications. Indicate any variances from the test
documentation (e.g., test changes or tests not executed). Specify the reason for each variance (or
specified group(s) of variances), or reference where it is recorded.\par

Evaluate the comprehensiveness of the testing process (e.g., coverage metrics, if specified) against the
comprehensiveness criteria specified in the Level Test Plan, if the plan exists.

\section{Rationale for Decisions}
Specify the issues that were considered for any decisions and the reason(s) for the selection of the
conclusion(s).

\section{Conclusions and Recommendations}
Specify an overall evaluation of each test item, including its limitations. This evaluation will be based
on the test results and on the item level pass/fail criteria. An estimate of failure risk may be included.
Recommend its status relative to availability for production use, and under what circumstances (e.g.,
immediately, with a specified subset of anomalies resolved, or never). This may include identification
of anomaly clusters in functionality and/or anomaly root cause analysis.
